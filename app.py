# -*- coding: utf-8 -*-
"""Copy of May 22.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wsn8k2j5HMalAorkmvAnIh01I-6zWJRG
"""

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.pipeline import Pipeline
import joblib
from transformers import pipeline as hf_pipeline
import re

# 1. Load datasets
df = pd.read_csv(
    "https://drive.google.com/uc?export=download&id=14D_HcvTFL63-KffCQLNFxGH-oY_knwmo",
    delimiter=';', header=None, names=['sentence', 'label']
)
ts_df = pd.read_csv(
    "https://drive.google.com/uc?export=download&id=1Vmr1Rfv4pLSlAUrlOCxAcszvlxJOSHrm",
    delimiter=';', header=None, names=['sentence', 'label']
)

df = pd.concat([df, ts_df], ignore_index=True)

df

total_rows = df.shape[0]

# % of null values
null_percent = df.isnull().mean() * 100

# % of duplicate rows
duplicate_rows = df.duplicated().sum()
duplicate_percent = (duplicate_rows / total_rows) * 100

print("Null Value Percentage:\n", null_percent)
print(f"\nðŸ“„ Duplicate Rows: {duplicate_rows} ({duplicate_percent:.2f}%)")
df.drop_duplicates(inplace=True)
def clean_text(text):
    if pd.isnull(text):
        return ""
    text = text.lower()
    text = re.sub(r"http\S+|www\S+|https\S+", '', text)         # Remove URLs
    text = re.sub(r'\@\w+|\#','', text)                         # Remove @ and #
    text = re.sub(r'[^a-z\s]', '', text)                        # Remove non-alphabetic characters
    text = re.sub(r'\s+', ' ', text).strip()                    # Normalize spaces
    return text
df['clean_sentence'] = df['sentence'].apply(clean_text)
# Load and prepare data
X = df['clean_sentence']
y = df['label']

# 1. Install necessary libraries in Colab (run once)
!pip install textblob
!python -m textblob.download_corpora

# === MODEL TRAINING CODE WITH REQUIRED CONCEPTS ===

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import CountVectorizer

# --- 1. Load and preprocess your DataFrame ---

tokenized = df['clean_sentence'].apply(str.split)

# --- 2. Build Vocabulary ---
vocab = Counter([token for sentence in tokenized for token in sentence])
vocab = {word: i+2 for i, (word, _) in enumerate(vocab.most_common())}
vocab['<PAD>'] = 0
vocab['<UNK>'] = 1

def encode(text):
    return [vocab.get(word, vocab['<UNK>']) for word in text]

encoded_texts = tokenized.apply(encode)

# --- 3. Pad Sequences ---
MAX_LEN = 32
def pad_sequence(seq):
    return seq[:MAX_LEN] + [vocab['<PAD>']] * max(0, MAX_LEN - len(seq))
padded = encoded_texts.apply(pad_sequence).tolist()

# --- 4. Encode Labels ---
le = LabelEncoder()
labels = le.fit_transform(df['label'])

# --- 5. Dataset + DataLoader ---
class EmotionDataset(Dataset):
    def __init__(self, X, y):
        self.X = torch.tensor(X, dtype=torch.long)
        self.y = torch.tensor(y, dtype=torch.long)

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

X_train, X_val, y_train, y_val = train_test_split(padded, labels, test_size=0.2, stratify=labels, random_state=42)
train_loader = DataLoader(EmotionDataset(X_train, y_train), batch_size=16, shuffle=True)
val_loader = DataLoader(EmotionDataset(X_val, y_val), batch_size=16)

# --- 6. Co-occurrence Matrix (Visualization Only) ---
vectorizer = CountVectorizer(max_features=20)
X_counts = vectorizer.fit_transform(df['clean_sentence'])
X_counts = (X_counts.T * X_counts)
X_counts.setdiag(0)
plt.figure(figsize=(18, 18))
sns.heatmap(X_counts.toarray(), xticklabels=vectorizer.get_feature_names_out(),
            yticklabels=vectorizer.get_feature_names_out(), cmap="YlGnBu", annot=True)
plt.title("Word Co-occurrence Matrix")
plt.show()

# --- 7. Positional Encoding ---
class PositionalEncoding(nn.Module):
    def __init__(self, d_model, max_len=MAX_LEN):
        super().__init__()
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        self.pe = pe.unsqueeze(0)

    def forward(self, x):
        return x + self.pe[:, :x.size(1)].to(x.device)

# --- 8. Transformer Model with Masking + Dropout for Bayesian Inference ---
class EmotionTransformer(nn.Module):
    def __init__(self, vocab_size, embed_dim, num_heads, num_classes):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=vocab['<PAD>'])
        self.pos_encoder = PositionalEncoding(embed_dim)
        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, batch_first=True)
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)
        self.dropout = nn.Dropout(0.3)
        self.fc = nn.Linear(embed_dim, num_classes)

    def forward(self, x):
        mask = (x == vocab['<PAD>'])
        x = self.embedding(x)
        x = self.pos_encoder(x)
        x = self.transformer(x, src_key_padding_mask=mask)
        x = self.dropout(x.mean(dim=1))  # mean pooling
        return self.fc(x)

# --- 9. Train the Model ---
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = EmotionTransformer(len(vocab), embed_dim=64, num_heads=4, num_classes=len(le.classes_)).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
criterion = nn.CrossEntropyLoss()

for epoch in range(5):
    model.train()
    total_loss = 0
    for X_batch, y_batch in train_loader:
        X_batch, y_batch = X_batch.to(device), y_batch.to(device)
        optimizer.zero_grad()
        logits = model(X_batch)
        loss = criterion(logits, y_batch)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    # Validation
    model.eval()
    correct = total = 0
    with torch.no_grad():
        for X_batch, y_batch in val_loader:
            X_batch, y_batch = X_batch.to(device), y_batch.to(device)
            outputs = model(X_batch)
            preds = torch.argmax(outputs, dim=1)
            correct += (preds == y_batch).sum().item()
            total += y_batch.size(0)

    print(f"Epoch {epoch+1} | Train Loss: {total_loss:.4f} | Val Accuracy: {correct / total:.4f}")

# Save model
torch.save(model.state_dict(), "emotion_transformer_model.pth")

! pip install textblob
! python -m textblob.download_corpora

import torch
import torch.nn.functional as F
import random
from textblob import TextBlob

# Load model
model.load_state_dict(torch.load("emotion_transformer_model.pth", map_location=device))
model.eval()

# Preprocess user input
def preprocess_input(text):
    tokens = text.lower().split()
    encoded = [vocab.get(token, vocab['<UNK>']) for token in tokens]
    padded = encoded[:MAX_LEN] + [vocab['<PAD>']] * max(0, MAX_LEN - len(encoded))
    return torch.tensor([padded], dtype=torch.long).to(device)

 3) Response logic
responses = {
    "sadness": [
        "Iâ€™m sorry youâ€™re feeling down. Would you like to step outside for fresh air together?",
        "Itâ€™s okay to feel sad. How about writing down one thing youâ€™re grateful for, then sharing it?",
        "I hear you. Maybe some gentle stretching or yoga could helpâ€”want to try?",
        "Maybe playing your favorite uplifting song and singing along could lift your moodâ€”shall we?",
        "Would you like to make a cup of tea or coffee and take a moment to yourself?",
        "How about watching a short funny video or meme to get a little smile?",
        "Perhaps texting someone you trust to let them know how you feel could lighten the load?",
        "Iâ€™m here for youâ€”would drawing or doodling to express your thoughts feel helpful?",
        "Want to go for a quick walk around the block and focus on the surroundings?",
        "Would counting down from ten on a deep breath then letting it go together help calm you?"
    ],
    "anger": [
        "That sounds really frustrating. Would you like to scream into a pillow to release tension?",
        "Itâ€™s understandable to be angry. How about taking five deep cleansing breaths with me?",
        "Would you like to scribble your anger onto paper and then tear it up to let go?",
        "Maybe going for a brisk walk or run could help burn off that steamâ€”want to try?",
        "How about doing a quick set of jumping jacks or push-ups to channel that energy?",
        "Perhaps lightly punching a cushion or using a stress ball could helpâ€”shall we?",
        "Would you like to try naming your anger and then talking it through step by step?",
        "Iâ€™m here to listenâ€”how about writing down whatâ€™s bothering you before we discuss?",
        "Maybe shouting out loud in a safe space could help your body release the tensionâ€”want to?",
        "Would taking a moment to count backward from ten and calm down before reacting help?"
    ],
    "love": [
        "Thatâ€™s wonderful. Would you like to send a quick thank-you message to someone who matters?",
        "How about writing down three reasons you feel this love to savor the moment?",
        "Would framing a photo or making a small memento to capture this feeling interest you?",
        "Perhaps planning a surprise treat or small gift for the person you love could extend this joy?",
        "Would you like to meditate for a few minutes, focusing on this loving feeling?",
        "Maybe sharing a heartfelt compliment or kind word with someone else could amplify it?",
        "How about creating a playlist of songs that bring up this loving energyâ€”want to try?",
        "Would writing a short love note to yourself reminding you why youâ€™re special feel good?",
        "Perhaps practicing a gratitude exercise and listing things you love about life could deepen it?",
        "Would you like to spend a moment hugging yourself or a loved one to hold onto this warmth?"
    ],
    "joy": [
        "This is fantastic. Would you like to celebrate with a quick dance or your favorite song?",
        "How about writing down three things that made you smile today to keep this feeling going?",
        "Would you treat yourself to something small, like your favorite snack, to savor the joy?",
        "Perhaps sharing this happy news with a friend or family member could double the fun?",
        "Would taking a few minutes to close your eyes and relive the moment in detail help?",
        "Maybe drawing or sketching how you feel could capture this joyâ€”want to try?",
        "How about doing a little spring or jumping movement to let the excitement out physically?",
        "Would you like to take a photo or video to remember this moment forever?",
        "Perhaps writing a cheerful note or text to someone could spread this joy outwards?",
        "Would pausing to notice the sensory detailsâ€”the sounds, sights, smells around youâ€”enhance this joy?"
    ],
    "surprise": [
        "Thatâ€™s unexpected! Would you like to pause and take a few steady breaths with me?",
        "Maybe jotting down what surprised you can help make sense of itâ€”want to try?",
        "How about asking a few questions to gather more info before we decide whatâ€™s next?",
        "Would taking a step back to look at the big picture help you process this surprise?",
        "Perhaps writing down possible positive outcomes could shift your perspectiveâ€”shall we?",
        "Would talking through what caught you off guard help make it less startling?",
        "How about listing what you know for sure then what youâ€™re unsure about to get clarity?",
        "Would taking a short breakâ€”walking or stretchingâ€”help you come back to it calmly?",
        "Perhaps imagining the best-case scenario of this surprise could spark excitementâ€”want to try?",
        "Would breathing in for four counts and out for four counts help steady your reaction?"
    ],
    "fear": [
        "Iâ€™m here with you. Would you like to try the 5-4-3-2-1 grounding exercise together?",
        "Itâ€™s okay to feel scared. How about exploring the worst-case scenario and its likelihood?",
        "Would gentle self-talk like 'Iâ€™ve overcome hard things before' help you feel safer?",
        "Perhaps folding your hands and focusing on that physical contact could soothe youâ€”want to?",
        "Would talking about what specifically worries you make it feel more manageable?",
        "How about taking a slow walk while naming safe places or people in your mind?",
        "Maybe placing a comforting objectâ€”like a blanket or stuffed animalâ€”near you could help?",
        "Would closing your eyes and taking three deep, slow breaths ease your anxiety?",
        "Perhaps writing down all your fears then challenging each one with facts could reduce themâ€”shall we?",
        "Would listening to a calming soundâ€”like soft music or nature soundsâ€”help ground you?"
    ],
    "disgust": [
        "That sounds really upsetting. Would stepping away for a moment or getting fresh air help?",
        "How about taking a few deep breaths while focusing on something neutral, like your breath?",
        "Would naming what you find off-putting allow you to release it more easily?",
        "Maybe holding a comforting itemâ€”like a soft fabricâ€”could help shift your focusâ€”want to try?",
        "Would distracting yourself briefly with a pleasant activity, like reading a favorite quote, help?",
        "Perhaps washing your hands or face could reset your sensory experienceâ€”shall we?",
        "Would taking a sip of water slowly and noticing its taste help bring you back?",
        "How about visualizing a calm, clean environment to replace the unpleasantness?",
        "Would listening to a soothing sound or song help you move past this feeling?",
        "Perhaps focusing on a positive memory and immersing yourself in it could override the disgust?"
    ],
    "neutral": [
        "Feeling neutral? Would trying a new hobby for five minutes spark some interest?",
        "How about picking one small task you enjoyâ€”like doodling or stretchingâ€”to break the neutral state?",
        "Would setting a quick mini-challengeâ€”like writing a two-line poemâ€”make things more engaging?",
        "Perhaps stepping outside for a moment of sunshine or fresh air could lift your moodâ€”want to try?",
        "Would calling or messaging a friend for a brief chat add some warmth to your day?",
        "How about listening to a motivating song and reflecting on why you chose it?",
        "Would writing down one thing youâ€™re curious about learning today help you feel more alive?",
        "Perhaps doing five jumping jacks or a quick stretch could energize youâ€”shall we?",
        "Would looking at a favorite photo or memory and reminiscing on it brighten your mood?",
        "How about drinking a glass of water mindfully, noticing its taste and temperature to ground yourself?"
    ]
}

# Suggestions
relaxation_resources = {
    "exercise": "Try this 5-4-3-2-1 grounding method:\n- 5 things you see\n- 4 you can touch\n- 3 you hear\n- 2 you smell\n- 1 you taste",
    "video": "Hereâ€™s a short calming video that might help: https://youtu.be/O-6f5wQXSu8"
}

# Keywords
help_keywords = ["suggest", "help", "calm", "exercise", "relax", "how can i", "any tips", "can u", "can you"]
negative_inputs = ["not good", "feel bad", "feel sad", "anxious", "depressed", "upset", "feel like shit", "stress", "worried"]
thank_you_inputs = ["thank", "thanks", "thank you"]
bye_inputs = ["bye", "goodbye", "see you", "take care", "ok bye", "exit", "quit"]

# Conversation state
awaiting_tip_type = False

# Correct spelling
def correct_spelling(text):
    return str(TextBlob(text).correct())

# Get response
def get_response(emotion, user_input):
    global awaiting_tip_type
    user_input_lower = user_input.lower()

    if any(bye in user_input_lower for bye in bye_inputs):
        return "Take care! Iâ€™m here whenever you want to talk. ðŸŒ¿", True

    if any(thank in user_input_lower for thank in thank_you_inputs):
        return "You're most welcome! I'm really glad I could support you. ðŸ’™", False

    # Awaiting video vs exercise clarification
    if awaiting_tip_type:
        if "video" in user_input_lower:
            awaiting_tip_type = False
            return relaxation_resources["video"], False
        elif "exercise" in user_input_lower or "excercise" in user_input_lower or "breathe" in user_input_lower:
            awaiting_tip_type = False
            return relaxation_resources["exercise"], False
        else:
            return "Just checking â€” would you prefer a calming video or a simple breathing exercise?", False

    # Offer relaxation suggestions
    if any(kw in user_input_lower for kw in help_keywords):
        awaiting_tip_type = True
        return "Would you prefer a short calming video or a simple breathing exercise?", False

    # Default: emotional response
    if emotion in responses:
        return random.choice(responses[emotion]), False
    else:
        return random.choice(responses["neutral"]), False

# Main chatbot loop
print("EmotiBot ðŸŒ¿: Hi! How are you feeling today? (Type 'exit' to quit)")

while True:
    user_input_raw = input("You: ").strip()
    user_input = correct_spelling(user_input_raw)

    if user_input.lower() in ['exit', 'quit']:
        print("EmotiBot ðŸŒ¿: Take care! Iâ€™m here whenever you want to talk.")
        break

    # Emotion prediction
    if any(phrase in user_input.lower() for phrase in negative_inputs):
        pred_emotion = "sadness"
    else:
        x = preprocess_input(user_input)
        model.train()
        with torch.no_grad():
            probs = torch.stack([F.softmax(model(x), dim=1) for _ in range(5)])
            avg_probs = probs.mean(dim=0)
            pred_idx = torch.argmax(avg_probs, dim=1).item()
        pred_emotion = le.classes_[pred_idx]

    # Generate response
    reply, should_exit = get_response(pred_emotion, user_input)
    print(f"EmotiBot ðŸŒ¿: {reply}")
    if should_exit:
        break

